{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install librosa\n",
    "%pip install tensorflow\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa as lb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('notes_v2/n_metadata.csv')\n",
    "print(f'Samples num: {metadata.shape[0]}\\nColumns num: {metadata.shape[1]}')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = metadata.groupby('Class_ID')['Class'].unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(path: str)  -> np.array:\n",
    "    data, _ = lb.load(path)\n",
    "    data = lb.feature.mfcc(data, n_mfcc=128)\n",
    "    data = np.mean(data, axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "\n",
    "for i, rows in tqdm(metadata.iterrows()):\n",
    "    path = rows['Sample']\n",
    "    x.append(feature_extractor(f'../input/guitar-notes-sound{path[7:]}'))\n",
    "    y.append(rows['Class_ID'])\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training , validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainval, xtest, ytrainval, ytest = train_test_split(x, y, test_size=0.1, stratify=y, random_state=42)\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(xtrainval, ytrainval, test_size=0.2, stratify=ytrainval,random_state=42)\n",
    "\n",
    "print('\\nNumber of samples for Train set :',xtrain.shape[0])\n",
    "print('Number of samples for Validation set :',xvalid.shape[0])\n",
    "print('Number of samples for Test set :',xtest.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        layers.Dense(1000, activation='relu', input_shape=(128,)),\n",
    "        layers.Dense(750, activation='relu'),\n",
    "        layers.Dense(500, activation='relu'),\n",
    "        layers.Dense(250, activation='relu'),\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(14, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "training = model.fit(xtrain, ytrain, validation_data=(xvalid, yvalid), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = pd.DataFrame(training.history)\n",
    "train_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(train_hist[['loss', 'val_loss']])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.title('Loss per Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(train_hist[['accuracy', 'val_accuracy']])\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.title('Accuracy per Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(ytest, axis=1)\n",
    "ypred = np.argmax(model.predict(xtest), axis=1)\n",
    "print('\\nConfusion Matrix: \\n\\n')\n",
    "print(confusion_matrix(ytrue, ypred))\n",
    "print('\\n\\nClassification Report: \\n\\n', classification_report(ytrue, ypred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
